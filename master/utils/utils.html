


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Utils &mdash; TorchTNT master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/torchtnt.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/torchtnt.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data" href="data.html" />
    <link rel="prev" title="TrainProgressMonitor" href="../framework/generated/torchtnt.framework.callbacks.TrainProgressMonitor.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

  
  
    <div id="redirect-banner" style="display: none">
      <p>
        This is the public documentation. There is internal documentation for Meta employees at
        <a href="https://www.internalfb.com/intern/staticdocs/torchtnt/">https://www.internalfb.com/intern/staticdocs/torchtnt/</a>
      </p>
    </div>
  

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (unstable)
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../checkpointing.html">Checkpointing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Framework</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../framework/unit.html">Unit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/auto_unit.html">AutoUnit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/eval.html">Evaluate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/predict.html">Predict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/fit.html">Fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/state.html">State</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/callbacks.html">Callbacks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Utils</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="loggers.html">Loggers</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Utils</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/utils/utils.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="module-torchtnt.utils">
<span id="utils"></span><h1>Utils<a class="headerlink" href="#module-torchtnt.utils" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">CPUStats</span></code><a class="headerlink" href="#torchtnt.utils.CPUStats" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.cpu_percent">
<code class="sig-name descname"><span class="pre">cpu_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.cpu_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.cpu_swap_percent">
<code class="sig-name descname"><span class="pre">cpu_swap_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.cpu_swap_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.cpu_vm_percent">
<code class="sig-name descname"><span class="pre">cpu_vm_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.cpu_vm_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.worker_cpu_time_system">
<code class="sig-name descname"><span class="pre">worker_cpu_time_system</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.worker_cpu_time_system" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.worker_cpu_time_user">
<code class="sig-name descname"><span class="pre">worker_cpu_time_user</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.worker_cpu_time_user" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.CPUStats.worker_rss">
<code class="sig-name descname"><span class="pre">worker_rss</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.CPUStats.worker_rss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">DDPStrategy</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">output_device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em><span class="n"><span class="pre">broadcast_buffers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em><span class="n"><span class="pre">process_group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">bucket_cap_mb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em><span class="n"><span class="pre">find_unused_parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">check_reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">gradient_as_bucket_view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">static_graph</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">comm_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">comm_hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/ddp_comm_hooks.html#torch.distributed.GradBucket" target="_blank" title="(in PyTorch v2.0)"><span class="pre">GradBucket</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/futures.html#torch.futures.Future" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Future</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">sync_batchnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.DDPStrategy" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataclass representing the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html" target="_blank">DistributedDataParallel</a> strategy.</p>
<p>Includes params for registering <a class="reference external" href="https://pytorch.org/docs/stable/ddp_comm_hooks.html" target="_blank">DDP communication hooks</a> and <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html" target="_blank">syncing batch norm</a>.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.broadcast_buffers">
<code class="sig-name descname"><span class="pre">broadcast_buffers</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.broadcast_buffers" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.bucket_cap_mb">
<code class="sig-name descname"><span class="pre">bucket_cap_mb</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">25</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.bucket_cap_mb" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.check_reduction">
<code class="sig-name descname"><span class="pre">check_reduction</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.check_reduction" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.comm_hook">
<code class="sig-name descname"><span class="pre">comm_hook</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/ddp_comm_hooks.html#torch.distributed.GradBucket" target="_blank" title="(in PyTorch v2.0)"><span class="pre">GradBucket</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/futures.html#torch.futures.Future" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Future</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.comm_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.comm_state">
<code class="sig-name descname"><span class="pre">comm_state</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.comm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.dim">
<code class="sig-name descname"><span class="pre">dim</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.find_unused_parameters">
<code class="sig-name descname"><span class="pre">find_unused_parameters</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.find_unused_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.gradient_as_bucket_view">
<code class="sig-name descname"><span class="pre">gradient_as_bucket_view</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.gradient_as_bucket_view" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.output_device">
<code class="sig-name descname"><span class="pre">output_device</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.output_device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.process_group">
<code class="sig-name descname"><span class="pre">process_group</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.process_group" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.static_graph">
<code class="sig-name descname"><span class="pre">static_graph</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.static_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.DDPStrategy.sync_batchnorm">
<code class="sig-name descname"><span class="pre">sync_batchnorm</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#torchtnt.utils.DDPStrategy.sync_batchnorm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">EarlyStopChecker</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'min'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">patience</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">min_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em><span class="n"><span class="pre">check_finite</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em><span class="n"><span class="pre">threshold_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'abs'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'rel'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'abs'</span></span></em>, <em><span class="n"><span class="pre">stopping_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">divergence_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker" title="Permalink to this definition">¶</a></dt>
<dd><p>Monitor a metric and signal if execution should stop early.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mode</strong> – one of <cite>min</cite>, <cite>max</cite>. In <cite>min</cite> mode, signal to stop early will be given when
the metric has stopped decreasing. In <cite>max</cite> mode, the signal is given when the
metric has stopped increasing.</li>
<li><strong>patience</strong> – Number of checks without improvement after which early stop will be signaled.</li>
<li><strong>min_delta</strong> – Must be &gt;= 0. Minimum absolute or relative change in the metric to qualify as
an improvement. In <cite>rel</cite> mode, improvement_threshold = best_val * ( 1 + min_delta ) in ‘max’
mode or best_val * ( 1 - min_delta ) in <cite>min</cite> mode. In <cite>abs</cite> mode, improvement_threshold =
best_val +  min_delta in <cite>max</cite> mode or best_val - threshold in <cite>min</cite> mode.</li>
<li><strong>check_finite</strong> – When set to <cite>True</cite>, signals early stop when metric becomes NaN or infinite.</li>
<li><strong>threshold_mode</strong> – one of <cite>abs</cite> or <cite>rel</cite>, threshold delta between checks for determining whether to stop.</li>
<li><strong>stopping_threshold</strong> – Signals early stop once the metric improves beyond this threshold.</li>
<li><strong>divergence_threshold</strong> – <p>Signals early stop once the metric becomes worse than this threshold.</p>
<dl class="docutils">
<dt>Raises:</dt><dd><dl class="docutils">
<dt>ValueError:</dt><dd>If <cite>mode</cite> is not <cite>min</cite> or <cite>max</cite>.</dd>
<dt>ValueError:</dt><dd>If <cite>min_delta</cite> &lt; 0.</dd>
<dt>ValueError:</dt><dd>If <cite>threshold_mode</cite> is not <cite>abs</cite> or <cite>rel</cite>.</dd>
</dl>
</dd>
</dl>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.check">
<code class="sig-name descname"><span class="pre">check</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.check" title="Permalink to this definition">¶</a></dt>
<dd><p>Check the current value of a metric and determine whether to stop or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>val</strong> – The metric that will be monitored to signal an early stop.
This should be either a single element tensor or a float.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A boolean indicating whether execution should stop early or not.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><strong>ValueError</strong> – If <cite>val</cite> is a tensor that does not contain 1 element.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.check_finite">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">check_finite</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.check_finite" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.divergence_threshold">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">divergence_threshold</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.divergence_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.load_state_dict">
<code class="sig-name descname"><span class="pre">load_state_dict</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads the current state from a <cite>state_dict</cite>.
This <cite>state_dict</cite> can be generated from <cite>state_dict()</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.min_delta">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">min_delta</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.min_delta" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.mode">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">mode</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'min'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.patience">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">patience</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.patience" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset back to the default state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.state_dict">
<code class="sig-name descname"><span class="pre">state_dict</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a <cite>state_dict</cite> to save the current state.
This <cite>state_dict</cite> can be reloaded using <cite>load_state_dict()</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.stopping_threshold">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">stopping_threshold</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.stopping_threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.EarlyStopChecker.threshold_mode">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">threshold_mode</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'abs'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'rel'</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.EarlyStopChecker.threshold_mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">FSDPStrategy</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">process_group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">sharding_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.ShardingStrategy" target="_blank" title="(in PyTorch v2.0)"><span class="pre">ShardingStrategy</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">cpu_offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.CPUOffload" target="_blank" title="(in PyTorch v2.0)"><span class="pre">CPUOffload</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">auto_wrap_policy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">backward_prefetch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.BackwardPrefetch" target="_blank" title="(in PyTorch v2.0)"><span class="pre">BackwardPrefetch</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">BackwardPrefetch.BACKWARD_PRE</span></span></em>, <em><span class="n"><span class="pre">ignored_modules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">sync_module_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">forward_prefetch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">limit_all_gathers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em><span class="n"><span class="pre">use_orig_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em><span class="n"><span class="pre">state_dict_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">StateDictType</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">state_dict_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">StateDictConfig</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">optim_state_dict_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">OptimStateDictConfig</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.FSDPStrategy" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataclass representing the <a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html" target="_blank">FullyShardedDataParallel</a> strategy</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.auto_wrap_policy">
<code class="sig-name descname"><span class="pre">auto_wrap_policy</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.auto_wrap_policy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.backward_prefetch">
<code class="sig-name descname"><span class="pre">backward_prefetch</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.BackwardPrefetch" target="_blank" title="(in PyTorch v2.0)"><span class="pre">BackwardPrefetch</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.backward_prefetch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.cpu_offload">
<code class="sig-name descname"><span class="pre">cpu_offload</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.CPUOffload" target="_blank" title="(in PyTorch v2.0)"><span class="pre">CPUOffload</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.cpu_offload" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.forward_prefetch">
<code class="sig-name descname"><span class="pre">forward_prefetch</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.forward_prefetch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.ignored_modules">
<code class="sig-name descname"><span class="pre">ignored_modules</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.ignored_modules" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.limit_all_gathers">
<code class="sig-name descname"><span class="pre">limit_all_gathers</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.limit_all_gathers" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.optim_state_dict_config">
<code class="sig-name descname"><span class="pre">optim_state_dict_config</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">OptimStateDictConfig</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.optim_state_dict_config" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.process_group">
<code class="sig-name descname"><span class="pre">process_group</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.process_group" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.sharding_strategy">
<code class="sig-name descname"><span class="pre">sharding_strategy</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.ShardingStrategy" target="_blank" title="(in PyTorch v2.0)"><span class="pre">ShardingStrategy</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.sharding_strategy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.state_dict_config">
<code class="sig-name descname"><span class="pre">state_dict_config</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">StateDictConfig</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.state_dict_config" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.state_dict_type">
<code class="sig-name descname"><span class="pre">state_dict_type</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">StateDictType</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.state_dict_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.sync_module_states">
<code class="sig-name descname"><span class="pre">sync_module_states</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.sync_module_states" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.FSDPStrategy.use_orig_params">
<code class="sig-name descname"><span class="pre">use_orig_params</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#torchtnt.utils.FSDPStrategy.use_orig_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.FlopTensorDispatchMode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">FlopTensorDispatchMode</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.FlopTensorDispatchMode" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager to measure flops of a module. Requires PyTorch 1.13+.</p>
<p>Flop count implementation based on
<a class="reference external" href="https://dev-discuss.pytorch.org/t/the-ideal-pytorch-flop-counter-with-torch-dispatch/505" target="_blank">https://dev-discuss.pytorch.org/t/the-ideal-pytorch-flop-counter-with-torch-dispatch/505</a></p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">copy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torcheval.tools.flops</span> <span class="kn">import</span> <span class="n">FlopTensorDispatchMode</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">FlopTensorDispatchMode</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">as</span> <span class="n">ftdm</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># count forward flops</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">res</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">module_input</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">flops_forward</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ftdm</span><span class="o">.</span><span class="n">flop_counts</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># reset count before counting backward flops</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">ftdm</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">res</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">flops_backward</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ftdm</span><span class="o">.</span><span class="n">flop_counts</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.FlopTensorDispatchMode.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.FlopTensorDispatchMode.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets current flop count.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.FullSyncPeriodicTimer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">FullSyncPeriodicTimer</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">interval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">timedelta</span></span></em>, <em><span class="n"><span class="pre">cpu_pg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ProcessGroup</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.FullSyncPeriodicTimer" title="Permalink to this definition">¶</a></dt>
<dd><p>Measures time (resets if given interval elapses) on rank 0
and propagates result to other ranks.
Propagation is done asynchronously from previous step
in order to avoid blocking of a training process.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.FullSyncPeriodicTimer.check">
<code class="sig-name descname"><span class="pre">check</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.FullSyncPeriodicTimer.check" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">GPUStats</span></code><a class="headerlink" href="#torchtnt.utils.GPUStats" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.fan_speed_percent">
<code class="sig-name descname"><span class="pre">fan_speed_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.fan_speed_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.memory_free_mb">
<code class="sig-name descname"><span class="pre">memory_free_mb</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.memory_free_mb" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.memory_used_mb">
<code class="sig-name descname"><span class="pre">memory_used_mb</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.memory_used_mb" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.temperature_gpu_celsius">
<code class="sig-name descname"><span class="pre">temperature_gpu_celsius</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.temperature_gpu_celsius" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.temperature_memory_celsius">
<code class="sig-name descname"><span class="pre">temperature_memory_celsius</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.temperature_memory_celsius" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.utilization_gpu_percent">
<code class="sig-name descname"><span class="pre">utilization_gpu_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.utilization_gpu_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.GPUStats.utilization_memory_percent">
<code class="sig-name descname"><span class="pre">utilization_memory_percent</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#torchtnt.utils.GPUStats.utilization_memory_percent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">ModuleSummary</span></code><a class="headerlink" href="#torchtnt.utils.ModuleSummary" title="Permalink to this definition">¶</a></dt>
<dd><p>Summary of module and its submodules. It collects the following information:</p>
<ul class="simple">
<li>Name</li>
<li>Type</li>
<li>Number of parameters</li>
<li>Number of trainable parameters</li>
<li>Estimated size in bytes</li>
<li>Whether this module contains uninitialized parameters</li>
<li>FLOPs for forward (“?” meaning not calculated)</li>
<li>FLOPs for backward (“?” meaning not calculated)</li>
<li>Input shape (“?” meaning not calculated)</li>
<li>Output shape (“?” meaning not calculated)</li>
<li>Forward elapsed time in ms (“?” meaning not calculated)</li>
</ul>
<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.flops_backward">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">flops_backward</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'?'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.flops_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total FLOPs for backward calculation using this module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.flops_forward">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">flops_forward</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'?'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.flops_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total FLOPs for forward calculation using this module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.forward_elapsed_time_ms">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">forward_elapsed_time_ms</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'?'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.forward_elapsed_time_ms" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the forward time of the module in ms.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.has_uninitialized_param">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">has_uninitialized_param</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.has_uninitialized_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns if a parameter in this module is uninitialized</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.in_size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">in_size</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'?'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.in_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the input size of the module</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.module_name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">module_name</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.module_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the name of this module</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.module_type">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">module_type</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.module_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the type of this module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.num_parameters">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">num_parameters</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.num_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of parameters in this module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.num_trainable_parameters">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">num_trainable_parameters</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.num_trainable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of trainable parameters (requires_grad=True)
in this module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.out_size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">out_size</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'?'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.out_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the output size of the module</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.size_bytes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">size_bytes</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.size_bytes" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total estimated size in bytes of a module.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.ModuleSummary.submodule_summaries">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">submodule_summaries</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.module_summary.ModuleSummary"><span class="pre">ModuleSummary</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torchtnt.utils.ModuleSummary.submodule_summaries" title="Permalink to this definition">¶</a></dt>
<dd><p>A Dict with the names of submodules as keys and corresponding <a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.ModuleSummary"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleSummary</span></code></a>
objects as values. These can be traversed for visualization.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">PGWrapper</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">pg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.PGWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper around ProcessGroup that allows collectives to be issued in a
consistent fashion regardless of the following scenarios:</p>
<blockquote>
<div>pg is None, distributed is initialized:     use WORLD as pg
pg is None, distributed is not initialized: single process app
pg is not None:                             use pg</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.all_gather_object">
<code class="sig-name descname"><span class="pre">all_gather_object</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">obj_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.all_gather_object" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.barrier">
<code class="sig-name descname"><span class="pre">barrier</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.barrier" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.broadcast_object_list">
<code class="sig-name descname"><span class="pre">broadcast_object_list</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">obj_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">src</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.broadcast_object_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.get_rank">
<code class="sig-name descname"><span class="pre">get_rank</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.get_rank" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.get_world_size">
<code class="sig-name descname"><span class="pre">get_world_size</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.get_world_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.PGWrapper.scatter_object_list">
<code class="sig-name descname"><span class="pre">scatter_object_list</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">output_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">input_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">src</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.PGWrapper.scatter_object_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.Progress">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">Progress</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">num_epochs_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em><span class="n"><span class="pre">num_steps_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em><span class="n"><span class="pre">num_steps_completed_in_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.Progress" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to track progress during the loop. Includes state_dict/load_state_dict for convenience for checkpointing.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.increment_epoch">
<code class="sig-name descname"><span class="pre">increment_epoch</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.Progress.increment_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Increment the epochs completed and resets the steps completed within the epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.increment_step">
<code class="sig-name descname"><span class="pre">increment_step</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.Progress.increment_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Increment the step counts completed and completed within the epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.load_state_dict">
<code class="sig-name descname"><span class="pre">load_state_dict</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.Progress.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Restores a Progress instance from a state_dict in accordance with Stateful protocol.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.num_epochs_completed">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">num_epochs_completed</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.Progress.num_epochs_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of epochs completed thus far in loop.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.num_steps_completed">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">num_steps_completed</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.Progress.num_steps_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of steps completed thus far in loop.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.num_steps_completed_in_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><code class="sig-name descname"><span class="pre">num_steps_completed_in_epoch</span></code><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#torchtnt.utils.Progress.num_steps_completed_in_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of steps completed thus far in epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Progress.state_dict">
<code class="sig-name descname"><span class="pre">state_dict</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.Progress.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a state_dict of a Progress instance in accordance with Stateful protocol.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.RSSProfiler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">RSSProfiler</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">interval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">timedelta</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">datetime.timedelta(microseconds=100000)</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.RSSProfiler" title="Permalink to this definition">¶</a></dt>
<dd><p>A profiler that periodically measures RSS (resident set size) delta.</p>
<p>The baseline RSS is measured when the profiler is initialized.
The RSS result is stored in the rss_deltas_bytes dict of the class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.RSSProfiler.interval">
<code class="sig-name descname"><span class="pre">interval</span></code><a class="headerlink" href="#torchtnt.utils.RSSProfiler.interval" title="Permalink to this definition">¶</a></dt>
<dd><p>The interval for measuring RSS. The default value is 100ms.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.RSSProfiler.rss_deltas_bytes">
<code class="sig-name descname"><span class="pre">rss_deltas_bytes</span></code><a class="headerlink" href="#torchtnt.utils.RSSProfiler.rss_deltas_bytes" title="Permalink to this definition">¶</a></dt>
<dd><p>The RSS delta bytes stored as dict. Key is the name for the profiling round, value is the list of RSS delta bytes captured periodically.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.RSSProfiler.profile">
<code class="sig-name descname"><span class="pre">profile</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Generator</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.RSSProfiler.profile" title="Permalink to this definition">¶</a></dt>
<dd><p>Profile the current process and store the results with a custom name as the key.</p>
<p>Profile the process by starting a separate thread to capture the RSS periodically.
The RSS result is stored in the rss_deltas_bytes dict of the class with the provided name as the key.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name</strong> – The name for the profiling round.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.RSSProfiler.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.RSSProfiler.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the stored rss_deltas_bytes dict to empty.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.Stateful">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">Stateful</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.Stateful" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the interface for checkpoint saving and loading.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Stateful.load_state_dict">
<code class="sig-name descname"><span class="pre">load_state_dict</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.Stateful.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Stateful.state_dict">
<code class="sig-name descname"><span class="pre">state_dict</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.Stateful.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torchtnt.utils.TLRScheduler">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">TLRScheduler</span></code><a class="headerlink" href="#torchtnt.utils.TLRScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchtnt.utils.Timer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">Timer</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span></em>, <em><span class="n"><span class="pre">cuda_sync</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchtnt.utils.Timer" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Timer.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.Timer.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the recorded_durations to an empty list</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchtnt.utils.Timer.time">
<code class="sig-name descname"><span class="pre">time</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">action_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Generator</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.Timer.time" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager for timing a code block, with optional cuda synchronization and verbose timing.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>action_name</strong> – the name under which to store the timing of what is enclosed in the context manager.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.all_gather_tensors">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">all_gather_tensors</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a></span></em>, <em><span class="n"><span class="pre">group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.all_gather_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to gather tensors from several distributed processes onto a list that is broadcasted to all processes.
Works on tensors that have the same number of dimensions, but where each dimension may differ. In this case
tensors are padded, gathered and then trimmed to secure equal workload for all processes.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>result</strong> – the value to sync</li>
<li><strong>group</strong> – the process group to gather results from. Defaults to all processes (world)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>list with size equal to the process group where</dt><dd><p>gathered_result[i] corresponds to result tensor from process i</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">gathered_result</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.attach_oom_observer">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">attach_oom_observer</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em><span class="n"><span class="pre">trace_max_entries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000000</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.attach_oom_observer" title="Permalink to this definition">¶</a></dt>
<dd><p>Attaches a function to record the PyTorch memory snapshot when an out of memory error occurs.</p>
<p>For more information, see this <a class="reference external" href="https://zdevito.github.io/2022/08/16/memory-snapshots.html" target="_blank">blog post</a> .</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>output_dir</strong> (<em>str</em>) – The directory to save the memory snapshot.</li>
<li><strong>trace_max_entries</strong> (<em>int</em><em>, </em><em>optional</em>) – The maximum number of trace entries to record. Defaults to 1000000.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Outputs are only saved if running on a host with CUDA devices available.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.barrier">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">barrier</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.barrier" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a synchronization point across all processes when using distributed.
If torch.distributed is initialized, this function will invoke a barrier across the global process group.
For more granular process group wrapping, please refer to <a class="reference internal" href="#torchtnt.utils.PGWrapper" title="torchtnt.utils.PGWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">PGWrapper</span></code></a>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.close_progress_bar">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">close_progress_bar</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">progress_bar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tqdm_asyncio</span></span></em>, <em><span class="n"><span class="pre">num_steps_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">refresh_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.close_progress_bar" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.convert_precision_str_to_dtype">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">convert_precision_str_to_dtype</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" target="_blank" title="(in PyTorch v2.0)"><span class="pre">dtype</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.convert_precision_str_to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts precision as a string to a torch.dtype</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>precision</strong> – string containing the precision</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><strong>ValueError if an invalid precision string is passed.</strong> – </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.copy_data_to_device">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">copy_data_to_device</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">T</span></span></em>, <em><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></em>, <em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#torchtnt.utils.copy_data_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that recursively copies data to a torch.device.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> – The data to copy to device</li>
<li><strong>device</strong> – The device to which the data should be copied</li>
<li><strong>args</strong> – positional arguments that will be passed to the <cite>to</cite> call</li>
<li><strong>kwargs</strong> – keyword arguments that will be passed to the <cite>to</cite> call</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The data on the correct device</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.create_progress_bar">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">create_progress_bar</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="o"><span class="pre">*</span></span></em>, <em><span class="n"><span class="pre">desc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em><span class="n"><span class="pre">num_epochs_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">num_steps_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">max_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">max_steps_per_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tqdm_asyncio</span></span></span><a class="headerlink" href="#torchtnt.utils.create_progress_bar" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.days_to_secs">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">days_to_secs</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">days</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.days_to_secs" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert time from days to seconds</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_device_from_env">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_device_from_env</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></span><a class="headerlink" href="#torchtnt.utils.get_device_from_env" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that gets the torch.device based on the current environment.</p>
<p>This currently supports only CPU and GPU devices. If CUDA is available, this function also sets the CUDA device.</p>
<p>Within a distributed context, this function relies on the <code class="docutils literal notranslate"><span class="pre">LOCAL_RANK</span></code> environment variable
to be made available by the program launcher for setting the appropriate device index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><strong>RuntimeError</strong> – If <code class="docutils literal notranslate"><span class="pre">LOCAL_RANK</span></code> is outside the range of available GPU devices.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_filesystem">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_filesystem</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AbstractFileSystem</span></span></span><a class="headerlink" href="#torchtnt.utils.get_filesystem" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the appropriate filesystem to use when handling the given path.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_global_rank">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_global_rank</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchtnt.utils.get_global_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Get rank using torch.distributed if available. Otherwise, the RANK env var instead if initialized.
Returns 0 if neither condition is met.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_local_rank">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_local_rank</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchtnt.utils.get_local_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Get rank using the <code class="docutils literal notranslate"><span class="pre">LOCAL_RANK</span></code> environment variable, if populated: <a class="reference external" href="https://pytorch.org/docs/stable/elastic/run.html#environment-variables" target="_blank">https://pytorch.org/docs/stable/elastic/run.html#environment-variables</a>
Defaults to 0 if <code class="docutils literal notranslate"><span class="pre">LOCAL_RANK</span></code> is not set.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_module_summary">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_module_summary</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em>, <em><span class="n"><span class="pre">module_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">module_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">MutableMapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.module_summary.ModuleSummary"><span class="pre">ModuleSummary</span></a></span></span><a class="headerlink" href="#torchtnt.utils.get_module_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a <a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.ModuleSummary"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleSummary</span></code></a> object, then assign its values and generate submodule tree.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>module</strong> – The module to be summarized.</li>
<li><strong>module_args</strong> – A tuple of arguments for the module to run and calculate FLOPs and activation sizes.</li>
<li><strong>module_kwargs</strong> – <p>Any kwarg arguments to be passed into the module’s forward function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">To calculate FLOPs, you must use PyTorch 1.13 or greater.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If module contains any lazy submodule, we will NOT calculate FLOPs.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Currently only modules that output a single tensor are supported.
TODO: to support more flexible output for module.</p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_nvidia_smi_gpu_stats">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_nvidia_smi_gpu_stats</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchtnt.utils.GPUStats" title="torchtnt.utils.device.GPUStats"><span class="pre">GPUStats</span></a></span></span><a class="headerlink" href="#torchtnt.utils.get_nvidia_smi_gpu_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Get GPU stats from nvidia smi.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>device</strong> – A GPU torch.device to get stats from.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">a dict that maps gpu stats to their values.<dl class="docutils">
<dt>Keys:</dt><dd><ul class="simple">
<li>’utilization_gpu_percent’</li>
<li>’utilization_memory_percent’</li>
<li>’fan_speed_percent’</li>
<li>’memory_used_mb’</li>
<li>’memory_free_mb’</li>
<li>’temperature_gpu_celsius’</li>
<li>’temperature_memory_celsius’</li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict (str, float)</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><strong>FileNotFoundError</strong> – If nvidia-smi command is not found.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_process_group_backend_from_device">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_process_group_backend_from_device</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#torchtnt.utils.get_process_group_backend_from_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that gets the default process group backend from the device.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_psutil_cpu_stats">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_psutil_cpu_stats</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchtnt.utils.CPUStats" title="torchtnt.utils.device.CPUStats"><span class="pre">CPUStats</span></a></span></span><a class="headerlink" href="#torchtnt.utils.get_psutil_cpu_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Get CPU process stats using psutil.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a dict that maps cpu stats to their values.<p>Keys:</p>
<blockquote>
<div><ul class="simple">
<li>’cpu_vm_percent’</li>
<li>’cpu_percent’</li>
<li>’cpu_swap_percent’</li>
</ul>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">Dict[str, float]</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_python_version">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_python_version</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Version</span></span></span><a class="headerlink" href="#torchtnt.utils.get_python_version" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the current runtime Python version as a Version.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># if running in Python 3.8.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">get_python_version</span><span class="p">()</span>
<span class="s1">&#39;3.8.0&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_summary_table">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_summary_table</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module_summary</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.module_summary.ModuleSummary"><span class="pre">ModuleSummary</span></a></span></em>, <em><span class="n"><span class="pre">human_readable_nums</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#torchtnt.utils.get_summary_table" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a string summary_table, tabularizing the information in module_summary.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>module_summary</strong> – module_summary to be printed/tabularized</li>
<li><strong>human_readable_nums</strong> – set to False for exact (e.g. 1234 vs 1.2 K)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_tensor_size_bytes_map">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_tensor_size_bytes_map</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.get_tensor_size_bytes_map" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_timer_summary">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_timer_summary</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">timer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TimerProtocol</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#torchtnt.utils.get_timer_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a timer, generate a summary of all the recorded actions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>timer</strong> – the Timer object for which to generate a summary</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><strong>ValueError</strong> – If the input Timer has no recorded actions</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_torch_version">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_torch_version</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Version</span></span></span><a class="headerlink" href="#torchtnt.utils.get_torch_version" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the PyTorch version for the current runtime environment as a Version.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># if running PyTorch 1.12.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">get_torch_version</span><span class="p">()</span>
<span class="s1">&#39;1.12.0&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.get_world_size">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">get_world_size</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchtnt.utils.get_world_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get world size using torch.distributed if available. Otherwise, the WORLD_SIZE env var is used instead if initialized.
Returns 1 if neither condition is met.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.init_from_env">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">init_from_env</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span></em>, <em><span class="n"><span class="pre">device_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">dist_init_method_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'env'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'tcp'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'file'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'env'</span></span></em>, <em><span class="n"><span class="pre">pg_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">pg_timeout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">timedelta</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">datetime.timedelta(seconds=1800)</span></span></em>, <em><span class="n"><span class="pre">float32_matmul_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'high'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></span><a class="headerlink" href="#torchtnt.utils.init_from_env" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility function that initializes the device and process group, if applicable.</p>
<dl class="docutils">
<dt>The global process group is initialized only if:</dt><dd><ul class="simple">
<li>torch.distributed is available is not already initialized</li>
<li>the program has been launched on multiple processes</li>
</ul>
</dd>
</dl>
<p>This is intended as a convenience to include at the beginning of scripts that follow
a SPMD-style execution model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>device_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Device type to initialize. If None, device will be initialized
based on environment</li>
<li><strong>dist_init_method_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Method to initialize the process group. Must be one of “env”, “tcp”, or “file”.
For more information, see here: <a class="reference external" href="https://pytorch.org/docs/stable/distributed.html#initialization" target="_blank">https://pytorch.org/docs/stable/distributed.html#initialization</a></li>
<li><strong>pg_backend</strong> (<em>str</em><em>, </em><em>optional</em>) – The process group backend to use. If None, it will use the
default process group backend from the device</li>
<li><strong>pg_timeout</strong> (<em>timedelta</em><em>, </em><em>optional</em>) – Timeout for operations executed against the process
group. Default value equals 30 minutes</li>
<li><strong>float32_matmul_precision</strong> (<em>str</em><em>, </em><em>optional</em>) – The setting for torch’s precision of matrix multiplications.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The current device.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_out_of_cpu_memory">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_out_of_cpu_memory</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">exception</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaseException</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_out_of_cpu_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if the exception is related to CPU OOM</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_out_of_cuda_memory">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_out_of_cuda_memory</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">exception</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaseException</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_out_of_cuda_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if the exception is related to CUDA OOM</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_out_of_memory_error">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_out_of_memory_error</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">exception</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaseException</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_out_of_memory_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if an exception is due to an OOM based on error message</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_ge_1_13_1">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_ge_1_13_1</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_ge_1_13_1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_10">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_10</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_10" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_11">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_11</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_11" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_12">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_12</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_12" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_13">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_13</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_13" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_14">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_14</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_14" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_8">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_8</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_8" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_1_9">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_1_9</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_1_9" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_torch_version_geq_2_0">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_torch_version_geq_2_0</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_torch_version_geq_2_0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.is_windows">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">is_windows</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.is_windows" title="Permalink to this definition">¶</a></dt>
<dd><p>Is the current program running in the Windows operating system?</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.log_elapsed_time">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">log_elapsed_time</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">action_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em><span class="o"><span class="pre">*</span></span></em>, <em><span class="n"><span class="pre">cuda_sync</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Generator</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.log_elapsed_time" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility to measure and log elapsed time for a given event.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>action_name</strong> – the name of the event being timed.</li>
<li><strong>cuda_sync</strong> – Whether to synchronize the stream in order to measure the most accurate timings on CUDA. Defaults to True if CUDA is available.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><strong>ValueError</strong> – If cuda_sync is set to True but CUDA is not available.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.log_memory_snapshot">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">log_memory_snapshot</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.log_memory_snapshot" title="Permalink to this definition">¶</a></dt>
<dd><p>Writes the memory snapshots to the provided <code class="docutils literal notranslate"><span class="pre">output_dir</span></code>.
For more information, see this <a class="reference external" href="https://zdevito.github.io/2022/08/16/memory-snapshots.html" target="_blank">blog post</a> .</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>output_dir</strong> (<em>str</em>) – The directory to save the memory snapshot.</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Outputs are only saved if running on a host with CUDA devices available.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.maybe_enable_tf32">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">maybe_enable_tf32</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'high'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.maybe_enable_tf32" title="Permalink to this definition">¶</a></dt>
<dd><p>Conditionally sets the precision of float32 matrix multiplications.</p>
<p>For more information, see the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html" target="_blank">PyTorch docs</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>precision</strong> – The setting to determine which datatypes to use for matrix multiplication.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.measure_rss_deltas">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">measure_rss_deltas</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">rss_deltas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em><span class="n"><span class="pre">interval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">timedelta</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">datetime.timedelta(microseconds=100000)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Generator</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchtnt.utils.measure_rss_deltas" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager that periodically measures RSS (resident set size) delta.</p>
<p>The baseline RSS is measured when the context manager is initialized.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rss_deltas</strong> – The list to which the measured RSS deltas (measured in
bytes) are appended.</li>
<li><strong>interval</strong> – The interval at which RSS deltas are measured.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.prepare_ddp">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">prepare_ddp</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em>, <em><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></em>, <em><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchtnt.utils.DDPStrategy" title="torchtnt.utils.prepare_module.DDPStrategy"><span class="pre">DDPStrategy</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel" target="_blank" title="(in PyTorch v2.0)"><span class="pre">DistributedDataParallel</span></a></span></span><a class="headerlink" href="#torchtnt.utils.prepare_ddp" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility to move a module to device and wrap in <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html" target="_blank">DistributedDataParallel</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>module</strong> – module to be wrapped in DDP</li>
<li><strong>strategy</strong> – an instance of DDPStrategy which defines the settings of DDP APIs</li>
<li><strong>device</strong> – device to which module will be moved</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Examples::</dt><dd>strategy = DDPStrategy(find_unused_parameters=True, gradient_as_bucket_view=True)
module = nn.Linear(1, 1)
device = torch.device(“cuda”)
ddp_module = prepare_ddp(module, strategy, device)</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.prepare_fsdp">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">prepare_fsdp</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em>, <em><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" target="_blank" title="(in PyTorch v2.0)"><span class="pre">device</span></a></span></em>, <em><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchtnt.utils.FSDPStrategy" title="torchtnt.utils.prepare_module.FSDPStrategy"><span class="pre">FSDPStrategy</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" target="_blank" title="(in PyTorch v2.0)"><span class="pre">dtype</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel" target="_blank" title="(in PyTorch v2.0)"><span class="pre">FullyShardedDataParallel</span></a></span></span><a class="headerlink" href="#torchtnt.utils.prepare_fsdp" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility to move a module to device and wrap in <a class="reference external" href="https://pytorch.org/docs/stable/fsdp.html" target="_blank">FullyShardedDataParallel</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>module</strong> – module to be wrapped in FSDP</li>
<li><strong>strategy</strong> – an instance of FSDPStrategy which defines the settings of FSDP APIs</li>
<li><strong>device</strong> – device to which module will be moved</li>
<li><strong>precision</strong> – precision to use when wrapping in FSDP</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Examples::</dt><dd>strategy = FSDPStrategy(limit_all_gathers=True)
module = nn.Linear(1, 1)
device = torch.device(“cuda”)
fsdp_module = prepare_fsdp(module, strategy, device)</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.prune_module_summary">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">prune_module_summary</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">module_summary</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchtnt.utils.ModuleSummary" title="torchtnt.utils.module_summary.ModuleSummary"><span class="pre">ModuleSummary</span></a></span></em>, <em><span class="o"><span class="pre">*</span></span></em>, <em><span class="n"><span class="pre">max_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.prune_module_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Prune the module summaries that are deeper than max_depth in the module
summary tree. The ModuleSummary object is prunned inplace.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>module_summary</strong> – Root module summary to prune.</li>
<li><strong>max_depth</strong> – The maximum depth of module summaries to keep.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><strong>ValueError</strong> – If <cite>max_depth</cite> is an int less than 1</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_critical">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_critical</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Logger</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_critical" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_debug">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_debug</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Logger</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_debug" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_error">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_error</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Logger</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_info">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_info</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Logger</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_info" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_print">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_print</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_print" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.rank_zero_warn">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">rank_zero_warn</span></code><span class="sig-paren">(</span><em><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Logger</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.rank_zero_warn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.record_data_in_stream">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">record_data_in_stream</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">T</span></span></em>, <em><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.cuda.Stream.html#torch.cuda.Stream" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Stream</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.record_data_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>As mentioned in
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html" target="_blank">https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html</a>, PyTorch
uses the “caching allocator” for memory allocation for tensors. When a tensor is
freed, its memory is likely to be reused by newly constructed tensors. By default,
this allocator traces whether a tensor is still in use by only the CUDA stream where
it was created. When a tensor is used by additional CUDA streams, we need to call
<cite>record_stream</cite> to tell the allocator about these streams. Otherwise, the allocator
might free the underlying memory of the tensor once it is no longer used by the
creator stream. This is a notable programming trick when we write programs using
multiple CUDA streams.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> – The data on which to call record_stream</li>
<li><strong>stream</strong> – The CUDA stream with which to call record_stream</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.seed">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">seed</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">deterministic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that sets seed for pseudo-random number generators across commonly used libraries.</p>
<p>This seeds PyTorch, NumPy, and the python.random module.
For more details, see <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html" target="_blank">https://pytorch.org/docs/stable/notes/randomness.html</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>seed</strong> – the integer value seed.</li>
<li><strong>deterministic</strong> – Controls determinism settings within PyTorch.
If <cite>None</cite>, don’t set any PyTorch global values.
If “default” or 0, don’t error or warn on nondeterministic operations and additionally enable PyTorch CuDNN benchmark.
If “warn” or 1, warn on nondeterministic operations and disable PyTorch CuDNN benchmark.
If “error” or 2, error on nondeterministic operations and disable PyTorch CuDNN benchmark.
For more details, see <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.set_deterministic_debug_mode.html#torch.set_deterministic_debug_mode" target="_blank" title="(in PyTorch v2.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.set_deterministic_debug_mode()</span></code></a> and
<a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html#avoiding-nondeterministic-algorithms" target="_blank">https://pytorch.org/docs/stable/notes/randomness.html#avoiding-nondeterministic-algorithms</a>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><strong>ValueError</strong> – If the input seed value is outside the required range.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.sync_bool">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">sync_bool</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em><span class="n"><span class="pre">pg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ProcessGroup</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em><span class="n"><span class="pre">coherence_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'any'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'rank_zero'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'any'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchtnt.utils.sync_bool" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility to synchronize a boolean value across members of a provided process group.</p>
<p>In the case <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> is not available or initialized, the input <code class="docutils literal notranslate"><span class="pre">val</span></code> is returned.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>val</strong> (<em>bool</em>) – boolean value to synchronize</li>
<li><strong>pg</strong> – process group to use for synchronization. If not specified, the default process group is used.</li>
<li><strong>Union</strong><strong>[</strong><strong>str</strong> (<em>coherence_mode</em>) – the manner in which the boolean value should be synchronized. 5 options are currently supported:
1. any (default): If any rank provides a True value, all ranks should receive True.
2. all: Only if all ranks provide a True value should all ranks receive True.
3. rank_zero: Makes rank 0 process’s value the source of truth and broadcasts the result to all other processes.
4. If an integer N is provided, return True only if at least N processes provide a True value.
5. If a float F is provided, return True only if at least this ratio of processes provide a True value. The ratio provided should be in the range [0, 1].</li>
<li><strong>int</strong> – the manner in which the boolean value should be synchronized. 5 options are currently supported:
1. any (default): If any rank provides a True value, all ranks should receive True.
2. all: Only if all ranks provide a True value should all ranks receive True.
3. rank_zero: Makes rank 0 process’s value the source of truth and broadcasts the result to all other processes.
4. If an integer N is provided, return True only if at least N processes provide a True value.
5. If a float F is provided, return True only if at least this ratio of processes provide a True value. The ratio provided should be in the range [0, 1].</li>
<li><strong>float</strong><strong>]</strong> – the manner in which the boolean value should be synchronized. 5 options are currently supported:
1. any (default): If any rank provides a True value, all ranks should receive True.
2. all: Only if all ranks provide a True value should all ranks receive True.
3. rank_zero: Makes rank 0 process’s value the source of truth and broadcasts the result to all other processes.
4. If an integer N is provided, return True only if at least N processes provide a True value.
5. If a float F is provided, return True only if at least this ratio of processes provide a True value. The ratio provided should be in the range [0, 1].</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The synchronized boolean value.</p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">val</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># synced_val is True iff all ranks provide a True value to the function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">synced_val</span> <span class="o">=</span> <span class="n">sync_bool</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">coherence_mode</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">synced_val</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;success&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.transfer_batch_norm_stats">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">transfer_batch_norm_stats</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">src_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em>, <em><span class="n"><span class="pre">dst_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.transfer_batch_norm_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer batch norm statistics between two same models</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.transfer_weights">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">transfer_weights</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">src_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em>, <em><span class="n"><span class="pre">dst_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" target="_blank" title="(in PyTorch v2.0)"><span class="pre">Module</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.transfer_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchtnt.utils.update_progress_bar">
<code class="sig-prename descclassname"><span class="pre">torchtnt.utils.</span></code><code class="sig-name descname"><span class="pre">update_progress_bar</span></code><span class="sig-paren">(</span><em><span class="n"><span class="pre">progress_bar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tqdm_asyncio</span></span></em>, <em><span class="n"><span class="pre">num_steps_completed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em><span class="n"><span class="pre">refresh_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchtnt.utils.update_progress_bar" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data.html" class="btn btn-neutral float-right" title="Data" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../framework/generated/torchtnt.framework.callbacks.TrainProgressMonitor.html" class="btn btn-neutral" title="TrainProgressMonitor" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Utils</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/js/torchtnt.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>